f_TaxaDesocupadosBrasil


let
    Fonte = Table.FromRecords(
        {[CaminhoSist = Text.Replace(Caminho,"\","/"), DataIni = Date.ToText(Date.AddDays(MenorData, -14),"yyyy-MM-dd"), DataFim = DateTime.ToText(Date.EndOfMonth(Date.AddMonths(DateTime.LocalNow(),-2)),"yyyy-MM-dd")]},
        type table[CaminhoSist = Text.Type, DataIni = Text.Type, DataFim = Text.Type]
),
    #"Executar script Python1" = Python.Execute("# 'dataset' tem os dados de entrada para este script#(lf)# -*- encoding: utf-8 -*-#(lf)#import time#(lf)from selenium import webdriver#(lf)from selenium.webdriver.support.ui import WebDriverWait#(lf)from selenium.webdriver.common.by import By#(lf)from selenium.webdriver.support import expected_conditions as EC#(lf)from selenium.webdriver.common.keys import Keys#(lf)from selenium.webdriver.common.by import By#(lf)from selenium.common.exceptions import TimeoutException#(lf)from selenium.webdriver.common.action_chains import ActionChains#(lf)from selenium.webdriver.support import expected_conditions as EC#(lf)from selenium.webdriver.support.ui import WebDriverWait as wait#(lf)from webdriver_manager.chrome import ChromeDriverManager#(lf)import selenium.webdriver.support.ui as ui#(lf)from selenium.common.exceptions import *#(lf)from selenium.webdriver.chrome.options import Options#(lf)from selenium.common.exceptions import TimeoutException#(lf)# Import Select class#(lf)from selenium.webdriver.support.ui import Select#(lf)#(lf)from bs4 import BeautifulSoup#(lf)import html.parser #(lf)from collections import OrderedDict#(lf)import pandas as pd#(lf)import numpy as np#(lf)#from itertools import tee, repeat, zip_longest#(lf)from datetime import datetime#(lf)#(lf)#(lf)# Verifica se a pagina est carregada#(lf)def pag_loading(sdriver):#(lf)  while True:#(lf)    dx = sdriver.execute_script(""return document.readyState"")#(lf)    if dx == ""complete"":#(lf)      break#(lf)    else:#(lf)      yield False#(lf)  return #(lf)#(lf)def page_is_loading(driver):#(lf)    while True:#(lf)        x = driver.execute_script(""return document.readyState"")#(lf)        if x == ""complete"":#(lf)            return True#(lf)        else:#(lf)            yield False#(lf)#(lf)# Funçao de comparação de strings#(lf)def isEqual(a, b):#(lf)  # Premissa de que sejam iguais#(lf)  igual = True#(lf)#(lf)  # Primeiro obtem tamanhos#(lf)  a = str(a)#(lf)  b = str(b)#(lf)#(lf)  lena = len(a)#(lf)  lenb = len(b)#(lf)  if lena > lenb or lenb > lena:#(lf)      igual = False#(lf)#(lf)  # print('len a', lenA)#(lf)  # print('len b', lenB)#(lf)  # se passo dos comandos testar#(lf)  if igual:#(lf)    # ja que os tamanhos são iguais vamos verrer caracter#(lf)    # por caracter pelo tamnho de A#(lf)    for i in range(lena):#(lf)      # print(a[i:i+1], "" = "", b[i:i+1])#(lf)      if a[i:i+1] != b[i:i+1]:#(lf)          # print(""Diferente"")#(lf)          igual = False#(lf)          break#(lf)#(lf)  return igual#(lf)#(lf)#(lf)#(lf)#-------------------------------------------------------------------------------------#(lf)# INICIANDO O PROCESSO #(lf)#-------------------------------------------------------------------------------------#(lf)#(lf)options = Options()#(lf)options.add_argument(""start-maximized"")#(lf)options.add_experimental_option(""excludeSwitches"", [""enable-automation""])#(lf)options.add_experimental_option('useAutomationExtension', False)#(lf)options.add_argument('--disable-blink-features=AutomationControlled')#(lf)#options.add_argument('--headless')#(lf)options.add_argument(""--disable-xss-auditor"")#(lf)options.add_argument(""--disable-web-security"")#(lf)options.add_argument(""--allow-running-insecure-content"")#(lf)options.add_argument(""--no-sandbox"")#(lf)options.add_argument(""--disable-setuid-sandbox"")#(lf)options.add_argument(""--disable-webgl"")#(lf)options.add_argument(""--disable-popup-blocking"")#(lf)options.add_argument(""--disable-dev-shm-usage"")#(lf)options.add_argument(""--disable-gpu"")#(lf)options.add_argument(""--log-level=3"")#(lf)options.add_argument('--disable-logging')#(lf)# Passa a Url para WebDriver Selenium e carrega o google Chromme com a pagina#(lf)# Iniciando o driver#(lf)driver = webdriver.Chrome(ChromeDriverManager().install(),chrome_options=options)#(lf)  #(lf)# Wait for the page to load#(lf)driver.implicitly_wait(15)#(lf)#(lf)url1 = ""https://saoluis.giap.com.br/apex/saoluis/f?p=839:3""#(lf)#(lf)#(lf)# Cria variável para caminho de armazenamento dos arquivos#(lf)Caminho = Caminho = dataset['CaminhoSist'][0]#(lf)nomepasta = ""/ReceitasPublicas/Capitais""#(lf)basedir = Caminho + nomepasta + ""/SaoLuis""#(lf)# cria um diretório para armazenar o arquivo comparâmetro para não criar se já existir#(lf)os.makedirs(basedir, exist_ok=True)#(lf)#(lf)#(lf)# Nome do arquivo#(lf)nomearq = basedir + ""/sao_luis.csv""#(lf)#print(nomearq)#(lf)#(lf)# Separa o Ano Atual#(lf)AnoAtual = datetime.now().year - 1#(lf)#print(AnoAtual)#(lf)#(lf)# Identifica menorData#(lf)d_dataini = dataset['DataIni'][0]#(lf)#(lf)# Identifica a maiorData#(lf)d_datafim = dataset['DataFim'][0]#(lf)#(lf)#(lf)#(lf)# Verifica se o arquivo já existe#(lf)if os.path.isfile(nomearq):#(lf)  # Se existe abre e verifica qual a maior data para baixar os últimos 2 anos#(lf)  # abre no dataset#(lf)  dataset = pd.read_csv(nomearq, sep =';')#(lf)  # Transforma o type para numerico no ano#(lf)  dataset['ano'] = pd.to_numeric(dataset['ano'],errors = 'coerce')#(lf)  # Limita o arquivo #(lf)  dataset= dataset[dataset.ano < AnoAtual] #(lf)  # Salva o arquivo com menos 2 anos anos atuais#(lf)  dataset.to_csv(nomearq, index = False, sep =';')#(lf)  # Guarda a data para iniciar a busca dos novos dados#(lf)  strAnoAtual = str(AnoAtual) + ""-01-01""#(lf)  # Cria o intervalo de datas#(lf)  datesStart = pd.date_range(start=strAnoAtual, end=d_datafim, freq = 'MS')#(lf)  datesEnd = pd.date_range(start=strAnoAtual, end=d_datafim, freq = 'M')#(lf)  # Abro o arquivo para incluir os novos valores#(lf)  arq_csv = open(nomearq,""a"",encoding=""utf-8"")#(lf)else:#(lf)  # Caso contrário cria um novo arquivo csv#(lf)  arq_csv = open(nomearq,""w"",encoding=""utf-8"")#(lf)  tmp = ""coodigoIBGE,mes,ano,descricao,fonte,aplicacao,valorOrcadoAtualizado,valorOrcado,valorArrecadado""#(lf)  arq_csv.write(tmp + '\n')#(lf)#(lf)  # Cria o intervalo de datas#(lf)  datesStart = pd.date_range(start='2015-01-01', end=datafim, freq = 'MS')#(lf)  datesEnd = pd.date_range(start='2015-01-30', end=datafim, freq = 'M')#(lf)#(lf)  # Cria o intervalo de datas#(lf)  #datesStart = pd.date_range(start=d_dataini, end=d_datafim, freq = 'MS')#(lf)  #datesEnd = pd.date_range(start=d_dataini, end=d_datafim, freq = 'M')#(lf)#(lf)#(lf)i = 0#(lf)#(lf)while i<len(datesStart):#(lf)#(lf)  driver.get(url1)#(lf)  #(lf)  #      Datas para Url#(lf)  mes  = int(datesStart[i].strftime(""%m"")) #(lf)  ano  = int(datesStart[i].strftime(""%Y""))#(lf) #(lf)  ano_index = 0#(lf)  ano_ini = 2009#(lf)  # Indice do ano#(lf)  ano_index = ano - ano_ini#(lf)#(lf)  # Seleciona valor do ano#(lf)  categoria = driver.find_element(By.XPATH,""//select[@id='GLOBAL_EXERCICIO']"")#(lf)  drop = Select(categoria)#(lf)  drop.select_by_index(ano_index)#(lf)  #time.sleep(1)#(lf)#(lf)  # Seleciona indice do mes iicio#(lf)  # Find id of option#(lf)  categoria = driver.find_element_by_id('P3_MES_INICIAL')#(lf)  drop = Select(categoria)#(lf)  drop.select_by_index(mes)#(lf)#(lf)  # Seleciona indice do mes fim#(lf)  categoria = driver.find_element_by_id('P3_MES_FINAL')#(lf)  drop = Select(categoria)#(lf)  drop.select_by_index(mes)#(lf)#(lf)#(lf)  # Seleciona indice do camp data#(lf)  categoria = driver.find_element_by_id('P3_QUEBRA')#(lf)  drop = Select(categoria)#(lf)  drop.select_by_index(3)#(lf)#(lf)#(lf)  # Seleciona indice do camp orçamento#(lf)  categoria = driver.find_element_by_id('P3_TIPO_RECEITA')#(lf)  drop = Select(categoria)#(lf)  drop.select_by_index(1)#(lf)#(lf)  try:#(lf)      elem = driver.find_element_by_xpath(""//button[@id='B133250412938450781']"")#(lf)      elem.click()#(lf)  except:#(lf)      pass#(lf)#(lf)#(lf)  #print('ok..')#(lf)#(lf)#(lf)  # Extraindo o conteudo da pagina decodificada#(lf)  content = driver.page_source.encode('utf-8').strip()#(lf)#(lf)  # Passando para o Beautifulsoup como html#(lf)  soup = BeautifulSoup(content, 'html.parser')#(lf)#(lf)  html = soup.find(""table"",{""id"":""report_relatorio_pagina_3""}).findAll(""td"")#(lf)#(lf)#(lf)  cont = 1#(lf)#(lf)  tmp = """"#(lf)  coodigoIBGE = """"#(lf)  descricao = """"#(lf)  fonte = """"#(lf)  aplicacao = """"#(lf)  valorOrcadoAtualizado = """" #(lf)  valorOrcado = """"#(lf)  valorArrecadado = """"#(lf)  for td in html:#(lf)    #print(td)#(lf)#(lf)    # Se achar o total para o laço#(lf)    if ""Total:"" in td.text:#(lf)      break#(lf)#(lf)    if td == tmp:#(lf)      continue#(lf)#(lf)    if(cont == 1):#(lf)      descricao = td.text#(lf)      tmp = td#(lf)      #(lf)    if(cont == 2):  #(lf)      aplicacao = td.text#(lf)      tmp = td#(lf)#(lf)    if(cont == 3):  #(lf)      fonte = td.text#(lf)      tmp = td#(lf)      #(lf)    if(cont == 4):#(lf)      valorOrcadoAtualizado = td.text#(lf)      valorOrcadoAtualizado = valorOrcadoAtualizado.lstrip()#(lf)      valorOrcadoAtualizado = valorOrcadoAtualizado.rstrip()#(lf)      valorOrcadoAtualizado = valorOrcadoAtualizado.replace(""."","""")#(lf)      valorOrcadoAtualizado = valorOrcadoAtualizado.replace("","",""."")#(lf)      print(td.text)#(lf)      tmp = td#(lf)      #(lf)    if(cont == 5):#(lf)      valorOrcado = td.text#(lf)      valorOrcado = valorOrcado.lstrip()#(lf)      valorOrcado = valorOrcado.rstrip()#(lf)      valorOrcado = valorOrcado.replace(""."","""")#(lf)      valorOrcado = valorOrcado.replace("","",""."")#(lf)      tmp = td#(lf)      #(lf)    if(cont == 6): #(lf)      valorArrecadado = td.text#(lf)      valorArrecadado = valorArrecadado.lstrip()#(lf)      valorArrecadado = valorArrecadado.rstrip()#(lf)      valorArrecadado = valorArrecadado.replace(""."","""")#(lf)      valorArrecadado = valorArrecadado.replace("","",""."")#(lf)      tmp = td#(lf)      #(lf)      #print('----------------------------------------------------------')#(lf)      #print(descricao)#(lf)      #print(fonte)#(lf)      #print(aplicacao)#(lf)      #print(valorOrcadoAtualizado)#(lf)      #print(valorOrcado)#(lf)      #print(valorArrecadado)#(lf)      # Grava arquivo#(lf)      tmp = """"#(lf)      tmp = tmp + ""2111300,"" #(lf)      tmp = tmp + str(mes) + "","" + str(ano) + "","" + descricao + "","" + fonte + "",""#(lf)      tmp = tmp + aplicacao + "","" + valorOrcadoAtualizado + "","" + valorOrcado + "",""#(lf)      tmp = tmp + valorArrecadado + ','#(lf)#(lf)      coodigoIBGE = """"#(lf)      descricao = """"#(lf)      fonte = """"#(lf)      aplicacao = """"#(lf)      valorOrcadoAtualizado = """" #(lf)      valorOrcado = """"#(lf)      valorArrecadado = """"#(lf)      arq_csv.write(tmp + '\n')#(lf)      cont = 0#(lf)#(lf)    cont = cont + 1#(lf)#(lf)  # conta datsas#(lf)  i = i + 1#(lf)#(lf)# fecha csv#(lf)arq_csv.close()#(lf)# fecha driver#(lf)driver.close#(lf)#(lf)dataset = pd.read_csv(nomearq, sep =',')#(lf)#print(datetime.now())#(lf)",[dataset=Fonte])
in
    #"Executar script Python1"