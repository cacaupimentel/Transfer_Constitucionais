Cap_CampoGrande

let
    Fonte = Python.Execute("# -*- encoding: utf-8 -*-#(lf)#import time#(lf)import requests#(lf)import pandas as pd#(lf)from datetime import datetime#(lf)import os#(lf)#(lf)#(lf)#print(datetime.now())#(lf)# Lista para guardas os dados #(lf)dataset_list = [] #(lf)# Aqui são as variáveis que temos que pegar#(lf)list_cabe = [""idMuni"", ""ano"", ""Mes"", ""nomefonte"", ""categoria"", ""nomecategoria"", ""origem"", ""nomeorigem"", ""especie"", ""nomeespecie"",#(lf)             ""rubrica"", ""nomerubrica"", ""alinea"", ""nomealinea"", ""subalinea"", ""nomesubalinea"", ""prevista"", ""arrecadada""]#(lf)#(lf)#(lf)# Cria variável para caminho de armazenamento dos arquivos#(lf)Caminho = ""E:/MESTRADO/DISSERTACAO/Dados_Abertos""#(lf)nomepasta = ""/Banco_Central_do_Brasil/Operacoes_Credito""#(lf)basedir = Caminho + nomepasta + ""/DADOS""#(lf)# cria um diretório para armazenar o arquivo comparâmetro para não criar se já existir#(lf)os.makedirs(basedir, exist_ok=True)#(lf)#(lf)#(lf)# Nome do arquivo#(lf)nomearq = basedir + ""/campo_grande.csv""#(lf)#print(nomearq)#(lf)#(lf)# Separa o Ano Atual#(lf)AnoAtual = datetime.now().year - 1#(lf)#print(AnoAtual)#(lf)#(lf)# Verifica se o arquivo já existe#(lf)if os.path.isfile(nomearq):#(lf)  # Se existe abre e verifica qual a maior data para baixar os últimos 2 anos#(lf)  # abre no dataset#(lf)  datalista = pd.read_csv(nomearq, sep =';')#(lf)  # Transforma o type para numerico no ano#(lf)  datalista['ano'] = pd.to_numeric(datalista['ano'],errors = 'coerce')#(lf)  # Limita o arquivo #(lf)  datalista = datalista[datalista.ano < AnoAtual] #(lf)  # Salva o arquivo com menos 2 anos anos atuais#(lf)  datalista.to_csv(nomearq, index = False, sep =';')#(lf)  # Guarda a data para iniciar a busca dos novos dados#(lf)  strAnoAtual = str(AnoAtual) + ""-01-01""#(lf)  # Cria o intervalo de datas#(lf)  datesStart = pd.date_range(start=strAnoAtual, end='2022-09-30', freq = 'MS')#(lf)  datesEnd = pd.date_range(start=strAnoAtual, end='2022-09-30', freq = 'M')#(lf)  # Abro o arquivo para incluir os novos valores#(lf)  arq_csv = open(nomearq,""a"",encoding=""utf-8"")#(lf)else:#(lf)  # Caso contrário cria um novo arquivo csv#(lf)  arq_csv = open(nomearq,""w"",encoding=""utf-8"")#(lf)  tmp = ""idMuni;ano;Mes;nomefonte;categoria;nomecategoria;origem;nomeorigem;especie;nomeespecie;rubrica;nomerubrica;alinea;nomealinea;subalinea;nomesubalinea;prevista;arrecadada""#(lf)  arq_csv.write(tmp + '\n')#(lf)  # Cria o intervalo de datas#(lf)  datesStart = pd.date_range(start='2010-01-01', end='2022-09-30', freq = 'MS')#(lf)  datesEnd = pd.date_range(start='2010-01-01', end='2022-09-30', freq = 'M')#(lf)#(lf)#(lf)#(lf)#(lf)def buscar_dados(url):#(lf)    request = requests.get(url)#(lf)    print(request.content)#(lf)#(lf)#(lf)#https://data-export.campogrande.ms.gov.br/api/transparencia/receita/lista/#(lf)# ?consulta_post=receitas&draw=1#(lf)# &ano=2013#(lf)# &receita=1#(lf)# &data-inicial=01%2F01%2F2013#(lf)# &data-final=31%2F01%2F2013#(lf)# &orgao=33#(lf)# &categoria=1&file_type=csv#(lf)#(lf)#https://data-export.campogrande.ms.gov.br/api/transparencia/receita/lista/?consulta_post=receitas&draw=1&ano=2013&receita=1&data-inicial=01%2F01%2F2013&data-final=31%2F01%2F2013&orgao=33&categoria=1&file_type=csv#(lf)#(lf)#(lf)def cria_url(uano, udtini, udtfim):#(lf)  # String de pesquisa da url#(lf)  s = """"#(lf)  s = ""?consulta_post=receitas&draw=1""#(lf)  s = s + ""&ano="" + uano#(lf)  s = s + ""&receita=1""#(lf)  s = s + ""&data-inicial="" + udtini#(lf)  s = s + ""&data-final="" + udtfim#(lf)  s = s + ""&orgao=33&categoria=1&file_type=csv""#(lf)  # Monta base da consulta#(lf)  url = ""https://data-export.campogrande.ms.gov.br/api/transparencia/receita/lista/"" + s#(lf)#(lf)  #print(""Inicio: "",  dtInicio)#(lf)  #print(""Fim   : "", dtFim)#(lf)  #print('------------------------------------------------------------------------------------')#(lf)  #print(""webdriver gets url...."")#(lf)  #print(url)#(lf)#(lf)  return url#(lf)#(lf)#(lf)# Função para ler os arquivos das urls#(lf)def ler_arq_url(lcodmuni, lu, lmes):#(lf)  # Garda na variável a resposta para o método GET do site#(lf)  resposta = requests.get(lu)#(lf)  arq_json = resposta.json()#(lf)  # Transfora em dicionário#(lf)  objeto = dict()#(lf)  objeto = dict(arq_json)#(lf)#(lf)  # Varrendo a collection#(lf)  for key,value in objeto.items():#(lf)    if key == ""data"":#(lf)      dados = value#(lf)#(lf)      for k in dados: #(lf)        tmp = """" #(lf)        list_campos = []#(lf)        list_campos.append(lcodmuni)#(lf)        list_campos.append(k.get(""ano""))#(lf)        list_campos.append(lmes)#(lf)        list_campos.append(k.get(""nomefonte""))#(lf)        list_campos.append(k.get(""categoria""))#(lf)        list_campos.append(k.get(""nomecategoria""))#(lf)        list_campos.append(k.get(""origem'""))#(lf)        list_campos.append(k.get(""nomeorigem""))#(lf)        list_campos.append(k.get(""especie""))#(lf)        list_campos.append(k.get(""nomeespecie""))#(lf)        list_campos.append(k.get(""rubrica""))#(lf)        list_campos.append(k.get(""nomerubrica""))#(lf)        list_campos.append(k.get(""alinea""))#(lf)        list_campos.append(k.get(""nomealinea""))#(lf)        list_campos.append(k.get(""subalinea""))#(lf)        list_campos.append(k.get(""nomesubalinea""))#(lf)        list_campos.append(k.get(""prevista""))#(lf)        list_campos.append(k.get(""arrecadada""))#(lf)        # Grava arquivo#(lf)        tmp = lcodmuni + "";"" + str(k.get(""ano"")) + "";"" + str(lmes) + "";"" + str(k.get(""nomefonte"")) + "";"" + str(k.get(""categoria"")) + "";""#(lf)        tmp = tmp + str(k.get(""nomecategoria"")) + "";"" + str(k.get(""origem'"")) + "";"" + str(k.get(""nomeorigem"")) + "";"" + str(k.get(""especie"")) + "";""#(lf)        tmp = tmp + str(k.get(""nomeespecie"")) + "";"" + str(k.get(""rubrica"")) + "";"" + str(k.get(""alinea"")) + "";"" + str(k.get(""nomealinea"")) + "";""#(lf)        tmp = tmp + str(k.get(""subalinea"")) + "";""  + str(k.get(""nomesubalinea"")) + "";"" + str(k.get(""prevista"")) + "";""#(lf)        tmp = tmp + str(k.get(""arrecadada""))#(lf)        arq_csv.write(tmp + '\n')#(lf)#(lf)        dataset_list.append(list_campos)#(lf)#(lf)  #print(dataset_list)#(lf)  return dataset_list#(lf)#(lf)#(lf)# faz o laço para buscar os arquivos#(lf)i = 0#(lf)while i < len(datesStart):#(lf)  #  Converte as datas#(lf)  dtInicio = datesStart[i].strftime(""%d/%m/%Y"")#(lf)  dtFim = datesEnd[i].strftime(""%d/%m/%Y"")#(lf)#(lf)  # Datas para Url#(lf)  data_inicio = str(datesStart[i].strftime(""%d""))  + '%2F' + str(datesStart[i].strftime(""%m"")) + '%2F' + str(datesStart[i].strftime(""%Y""))#(lf)  data_final = str(datesEnd[i].strftime(""%d"")) + '%2F' + str(datesEnd[i].strftime(""%m"")) + '%2F' + str(datesEnd[i].strftime(""%Y""))#(lf)  #(lf)  #cria string da url da API#(lf)  url = cria_url(datesStart[i].strftime(""%Y""), data_inicio, data_final)#(lf)  #(lf)  # Consome a API lendo o arquivo json criado#(lf)  dataset_list = ler_arq_url(""50027404"", url, str(datesStart[i].strftime(""%m"")))#(lf) #(lf)  # Incrementa a contagem das datas#(lf)  i = i + 1#(lf)#(lf)#(lf)#(lf)arq_csv.write('\n')#(lf)# Fecha o WebBrowser#(lf)arq_csv.close()#(lf)#(lf)arqmuni = pd.DataFrame(dataset_list, columns=list_cabe)#(lf)#print(datetime.now())#(lf)"),
    #"Linhas Filtradas" = Table.SelectRows(Fonte, each ([Name] = "arqmuni")),
    arqmuni1 = #"Linhas Filtradas"{[Name="arqmuni"]}[Value],
    #"Tipo Alterado" = Table.TransformColumnTypes(arqmuni1,{{"idMuni", Int64.Type}, {"ano", type text}, {"Mes", type text}, {"nomefonte", type text}, {"categoria", Int64.Type}, {"nomecategoria", type text}, {"origem", type text}, {"nomeorigem", type text}, {"especie", Int64.Type}, {"nomeespecie", type text}, {"rubrica", Int64.Type}, {"nomerubrica", type text}, {"alinea", Int64.Type}, {"nomealinea", type text}, {"subalinea", Int64.Type}, {"nomesubalinea", type text}, {"prevista", Int64.Type}, {"arrecadada", type number}})
in
    #"Tipo Alterado"


METADADOS:
Receitas Correntes do Município de Campo Grande, disponível no site da Transparência

unidade: valores correntes

Fonte: https://transparencia.campogrande.ms.gov.br/consulta-de-receitas/



let
    Fonte = Table.FromRecords(
        {[CaminhoSist = Text.Replace(Text.Replace(Caminho,"\","/"), ":/", "://"), DataIni = Date.ToText(Date.AddDays(MenorData, -14),"yyyy-MM-dd"), DataFim = DateTime.ToText(Date.EndOfMonth(Date.AddMonths(DateTime.LocalNow(),-2)),"yyyy-MM-dd")]},
        type table[CaminhoSist = Text.Type, DataIni = Text.Type, DataFim = Text.Type]
),
    #"Executar script Python1" = Python.Execute("# 'dataset' tem os dados de entrada para este script#(lf)#(lf)# -*- encoding: utf-8 -*-#(lf)import requests#(lf)import pandas#(lf)import os#(lf)#(lf)from datetime import datetime#(lf)#(lf)#(lf)#(lf)#print(datetime.now())#(lf)# Lista para guardas os dados #(lf)dataset_list = [] #(lf)# Aqui são as variáveis que temos que pegar#(lf)list_cabe = [""idMuni"", ""ano"", ""Mes"", ""nomefonte"", ""categoria"", ""nomecategoria"", ""origem"", ""nomeorigem"", ""especie"", ""nomeespecie"",#(lf)             ""rubrica"", ""nomerubrica"", ""alinea"", ""nomealinea"", ""subalinea"", ""nomesubalinea"", ""prevista"", ""arrecadada""]#(lf)#(lf)#(lf)# Cria variável para caminho de armazenamento dos arquivos#(lf)basedir = dataset['CaminhoSist'][0] + ""/ReceitasPublicas/Capitais/CampoGrande/""#(lf)#(lf)# cria um diretório para armazenar o arquivo comparâmetro para não criar se já existir#(lf)os.makedirs(os.path.abspath(os.path.dirname(basedir)), exist_ok=True)#(lf)#(lf)# Nome do arquivo#(lf)nomearq = ""campo_grande.csv""#(lf)#(lf)# Separa o Ano Atual#(lf)AnoAtual = datetime.now().year - 1#(lf)#(lf)# Identifica menorData#(lf)d_dataini = dataset['DataIni'][0]#(lf)#(lf)# Identifica a maiorData#(lf)d_datafim = dataset['DataFim'][0]#(lf)#(lf)#(lf)# Verifica se o arquivo já existe#(lf)if os.path.isfile(os.path.join(basedir, nomearq)):#(lf)  # Se existe abre e verifica qual a maior data para baixar os últimos 2 anos#(lf)  # abre no dataset#(lf)  dataset = pandas.read_csv(os.path.join(basedir, nomearq), sep=';')#(lf)  # Transforma o type para numerico no ano#(lf)  dataset['ano'] = pandas.to_numeric(dataset['ano'], errors='coerce')#(lf)  # Limita o arquivo #(lf)  dataset= dataset[dataset.ano < AnoAtual] #(lf)  # Salva o arquivo com menos 2 anos anos atuais#(lf)  dataset.to_csv(os.path.join(basedir, nomearq), index = False, sep=';')#(lf)  # Guarda a data para iniciar a busca dos novos dados#(lf)  strAnoAtual = str(AnoAtual) + ""-01-01""#(lf)  # Cria o intervalo de datas#(lf)  datesStart = pandas.date_range(start=strAnoAtual, end=d_datafim, freq='MS')#(lf)  datesEnd = pandas.date_range(start=strAnoAtual, end=d_datafim, freq='M')#(lf)  # Abro o arquivo para incluir os novos valores#(lf)  arq_csv = open(os.path.join(basedir, nomearq),""a"",encoding=""utf-8"")#(lf)else:#(lf)  # Caso contrário cria um novo arquivo csv#(lf)  arq_csv = open(os.path.join(basedir, nomearq),""w"",encoding=""utf-8"")#(lf)  tmp = ""idMuni;ano;Mes;nomefonte;categoria;nomecategoria;origem;nomeorigem;especie;nomeespecie;rubrica;nomerubrica;alinea;nomealinea;subalinea;nomesubalinea;prevista;arrecadada""#(lf)  arq_csv.write(tmp + '\n')#(lf)  # Cria o intervalo de datas#(lf)  datesStart = pandas.date_range(start=d_dataini, end=d_datafim, freq='MS')#(lf)  datesEnd = pandas.date_range(start=d_dataini, end=d_datafim, freq='M')#(lf)#(lf)#(lf)#(lf)#(lf)def buscar_dados(url):#(lf)    request = requests.get(url)#(lf)    print(request.content)#(lf)#(lf)#(lf)# https://data-export.campogrande.ms.gov.br/api/transparencia/receita/lista/#(lf)# ?consulta_post=receitas&draw=1#(lf)# &ano=2013#(lf)# &receita=1#(lf)# &data-inicial=01%2F01%2F2013#(lf)# &data-final=31%2F01%2F2013#(lf)# &orgao=33#(lf)# &categoria=1&file_type=csv#(lf)#(lf)#https://data-export.campogrande.ms.gov.br/api/transparencia/receita/lista/?consulta_post=receitas&draw=1&ano=2013&receita=1&data-inicial=01%2F01%2F2013&data-final=31%2F01%2F2013&orgao=33&categoria=1&file_type=csv#(lf)#(lf)#(lf)def cria_url(uano, udtini, udtfim):#(lf)  # String de pesquisa da url#(lf)  s = """"#(lf)  s = ""?consulta_post=receitas&draw=1""#(lf)  s = s + ""&ano="" + uano#(lf)  s = s + ""&receita=1""#(lf)  s = s + ""&data-inicial="" + udtini#(lf)  s = s + ""&data-final="" + udtfim#(lf)  s = s + ""&orgao=33&categoria=1&file_type=csv""#(lf)  # Monta base da consulta#(lf)  url = ""https://data-export.campogrande.ms.gov.br/api/transparencia/receita/lista/"" + s#(lf)#(lf)  #print(""Inicio: "",  dtInicio)#(lf)  #print(""Fim   : "", dtFim)#(lf)  #print('------------------------------------------------------------------------------------')#(lf)  #print(""webdriver gets url...."")#(lf)  #print(url)#(lf)#(lf)  return url#(lf)#(lf)#(lf)# Função para ler os arquivos das urls#(lf)def ler_arq_url(lcodmuni, lu, lmes):#(lf)  # Garda na variável a resposta para o método GET do site#(lf)  resposta = requests.get(lu)#(lf)  arq_json = resposta.json()#(lf)  # Transfora em dicionário#(lf)  objeto = dict()#(lf)  objeto = dict(arq_json)#(lf)#(lf)  # Varrendo a collection#(lf)  for key,value in objeto.items():#(lf)    if key == ""data"":#(lf)      dados = value#(lf)#(lf)      for k in dados: #(lf)        tmp = """" #(lf)        list_campos = []#(lf)        list_campos.append(lcodmuni)#(lf)        list_campos.append(k.get(""ano""))#(lf)        list_campos.append(lmes)#(lf)        list_campos.append(k.get(""nomefonte""))#(lf)        list_campos.append(k.get(""categoria""))#(lf)        list_campos.append(k.get(""nomecategoria""))#(lf)        list_campos.append(k.get(""origem'""))#(lf)        list_campos.append(k.get(""nomeorigem""))#(lf)        list_campos.append(k.get(""especie""))#(lf)        list_campos.append(k.get(""nomeespecie""))#(lf)        list_campos.append(k.get(""rubrica""))#(lf)        list_campos.append(k.get(""nomerubrica""))#(lf)        list_campos.append(k.get(""alinea""))#(lf)        list_campos.append(k.get(""nomealinea""))#(lf)        list_campos.append(k.get(""subalinea""))#(lf)        list_campos.append(k.get(""nomesubalinea""))#(lf)        list_campos.append(k.get(""prevista""))#(lf)        list_campos.append(k.get(""arrecadada""))#(lf)        # Grava arquivo#(lf)        tmp = lcodmuni + "";"" + str(k.get(""ano"")) + "";"" + str(lmes) + "";"" + str(k.get(""nomefonte"")) + "";"" + str(k.get(""categoria"")) + "";""#(lf)        tmp = tmp + str(k.get(""nomecategoria"")) + "";"" + str(k.get(""origem'"")) + "";"" + str(k.get(""nomeorigem"")) + "";"" + str(k.get(""especie"")) + "";""#(lf)        tmp = tmp + str(k.get(""nomeespecie"")) + "";"" + str(k.get(""rubrica"")) + "";"" + str(k.get(""alinea"")) + "";"" + str(k.get(""nomealinea"")) + "";""#(lf)        tmp = tmp + str(k.get(""subalinea"")) + "";""  + str(k.get(""nomesubalinea"")) + "";"" + str(k.get(""prevista"")) + "";""#(lf)        tmp = tmp + str(k.get(""arrecadada""))#(lf)        arq_csv.write(tmp + '\n')#(lf)#(lf)        dataset_list.append(list_campos)#(lf)#(lf)  #print(dataset_list)#(lf)  return dataset_list#(lf)#(lf)#(lf)# faz o laço para buscar os arquivos#(lf)i = 0#(lf)while i < len(datesStart):#(lf)  #  Converte as datas#(lf)  dtInicio = datesStart[i].strftime(""%d/%m/%Y"")#(lf)  dtFim = datesEnd[i].strftime(""%d/%m/%Y"")#(lf)#(lf)  # Datas para Url#(lf)  data_inicio = str(datesStart[i].strftime(""%d""))  + '%2F' + str(datesStart[i].strftime(""%m"")) + '%2F' + str(datesStart[i].strftime(""%Y""))#(lf)  data_final = str(datesEnd[i].strftime(""%d"")) + '%2F' + str(datesEnd[i].strftime(""%m"")) + '%2F' + str(datesEnd[i].strftime(""%Y""))#(lf)  #(lf)  #cria string da url da API#(lf)  url = cria_url(datesStart[i].strftime(""%Y""), data_inicio, data_final)#(lf)  #(lf)  # Consome a API lendo o arquivo json criado#(lf)  dataset_list = ler_arq_url(""50027404"", url, str(datesStart[i].strftime(""%m"")))#(lf) #(lf)  # Incrementa a contagem das datas#(lf)  i = i + 1#(lf)#(lf)#(lf)#(lf)arq_csv.write('\n')#(lf)# Fecha o WebBrowser#(lf)arq_csv.close()#(lf)#(lf)dataset = pandas.DataFrame(dataset_list, columns=list_cabe)#(lf)",[dataset=Fonte]),
    #"Colunas Removidas" = Table.RemoveColumns(#"Executar script Python1",{"Name"}),
    #"Value Expandido" = Table.ExpandTableColumn(#"Colunas Removidas", "Value", {"idMuni", "ano", "Mes", "nomefonte", "categoria", "nomecategoria", "origem", "nomeorigem", "especie", "nomeespecie", "rubrica", "nomerubrica", "alinea", "nomealinea", "subalinea", "nomesubalinea", "prevista", "arrecadada"}, {"idMuni", "ano", "Mes", "nomefonte", "categoria", "nomecategoria", "origem", "nomeorigem", "especie", "nomeespecie", "rubrica", "nomerubrica", "alinea", "nomealinea", "subalinea", "nomesubalinea", "prevista", "arrecadada"})
in
    #"Value Expandido"